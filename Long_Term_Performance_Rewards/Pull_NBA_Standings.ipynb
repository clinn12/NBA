{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull NBA Standings Data \n",
    "##### Webscrapper to pull NBA Standings for the regular season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input to specify the year processing will begin\n",
    "start_year = 1960\n",
    "\n",
    "#Input to specify the file to load and save updated output\n",
    "file_path = 'nba_standings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Functions to Scrape and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_season_year():\n",
    "    \"\"\"\n",
    "    Determine the current NBA season year and whether it should be processed.\n",
    "\n",
    "    NBA seasons run from October through April.\n",
    "    - If today's date is in May or later, the regular season year is considered the *next* year.\n",
    "    - Processing is skipped for the current season if today's month is between June and October.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - year (int): The NBA season year (e.g., 2025).\n",
    "            - process_season (bool): True if the current season should be processed\n",
    "              (November–May), False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Identify Date\n",
    "    today = datetime.today()\n",
    "    \n",
    "    #Identify Year and Season\n",
    "    if today.month >= 5:  #May or later is considered next season year\n",
    "        year = today.year + 1\n",
    "    else:\n",
    "        year = today.year\n",
    "    process_season = not (5 <= today.month <= 10)  #Skip May–Oct\n",
    "    \n",
    "    #Return Objects\n",
    "    return year, process_season\n",
    "\n",
    "\n",
    "def load_existing_data(file_path, min_size_kb):\n",
    "    \"\"\"\n",
    "    Load existing NBA standings data from CSV if it exists and is large enough.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing standings.\n",
    "        min_size_kb (int, optional): Minimum file size in kilobytes to consider\n",
    "                                     the file valid. Defaults to 1 KB.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - DataFrame: Existing standings data, or an empty DataFrame if not found/invalid.\n",
    "            - set[int]: Unique season years already present in the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Identify File\n",
    "    if os.path.exists(file_path) and os.path.getsize(file_path) > (min_size_kb * 1024):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df, set(df[\"Year\"].unique())\n",
    "    \n",
    "    #Return Dataframe\n",
    "    return pd.DataFrame(), set()\n",
    "\n",
    "\n",
    "def fetch_standings_html(year):\n",
    "    \"\"\"\n",
    "    Fetch the NBA standings HTML page for a given season year.\n",
    "\n",
    "    Args:\n",
    "        year (int): The NBA season year (e.g., 2025 for the 2024–25 season).\n",
    "\n",
    "    Returns:\n",
    "        BeautifulSoup: Parsed HTML content of the standings page.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Scrape Basketball Reference\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_standings.html\"\n",
    "    html = urlopen(url)\n",
    "\n",
    "    #Return Results\n",
    "    return BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "\n",
    "def parse_standings(soup, year):\n",
    "    \"\"\"\n",
    "    Parse a standings HTML page into a cleaned pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML of the standings page.\n",
    "        year (int): The NBA season year.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Cleaned standings data with columns:\n",
    "            ['Team', 'W', 'L', 'WL_pct', 'GB', 'PPG', 'OPPG', 'SRS', 'Year', 'Conference'].\n",
    "\n",
    "    Notes:\n",
    "        - Only keeps rows with exactly 8 columns of data.\n",
    "        - Cleans up 'GB' values and strips punctuation from team names.\n",
    "        - Infers and forward-fills conference names.\n",
    "        - Removes conference and division header rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Identify Headers\n",
    "    headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')][:8]\n",
    "    \n",
    "    #Identify Rows\n",
    "    rows = soup.findAll('tr')[1:]\n",
    "\n",
    "    #Identify Rows that are Standings\n",
    "    standings = [\n",
    "        [tr.getText() for tr in rows[i].findAll(['th', 'td'])]\n",
    "        for i in range(len(rows))\n",
    "    ]\n",
    "\n",
    "    #Keep only valid rows\n",
    "    if year >= 1971:\n",
    "        standings = [lst for lst in standings if len(lst) == 8]  \n",
    "\n",
    "    #Create Dataframe and Rename Columns\n",
    "    df = pd.DataFrame(standings, columns=headers)\n",
    "    df.columns = ['Team', 'W', 'L', 'WL_pct', 'GB', 'PPG', 'OPPG', 'SRS']\n",
    "    \n",
    "    #Create Year\n",
    "    df['Year'] = year\n",
    "\n",
    "    #Clean GB\n",
    "    df['GB'] = df['GB'].replace({'—': 0, '-': 0})\n",
    "\n",
    "    #Clean Team Names\n",
    "    invalidchar = string.punctuation\n",
    "    df['Team'] = df['Team'].str.strip(invalidchar)\n",
    "\n",
    "    #Set Conference and Forward Fill\n",
    "    df['Conference'] = df['Team'].where(\n",
    "        df['Team'].isin(['Eastern Conference', 'Western Conference', 'Eastern Division', 'Western Division'])\n",
    "    )\n",
    "    df['Conference'] = df['Conference'].ffill()\n",
    "\n",
    "    #Remove Rows not related to a team\n",
    "    df = df[~df['Team'].str.contains(r'Conference|Division', na=False, case=False)]\n",
    "\n",
    "    #Remove observations where 'W' is null. These are obsercations that are not related to a team's performance\n",
    "    df = df[df['W'].notna()]\n",
    "    df = df[df['W'] != 'W']\n",
    "\n",
    "    #Drop Team Duplicates\n",
    "    df = df.drop_duplicates(subset=['Team'])\n",
    "\n",
    "    #Return Dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main script entry point for scraping and updating NBA standings data.\n",
    "\n",
    "    Workflow:\n",
    "        1. Determine the current season year and processing eligibility.\n",
    "        2. Load existing data (if available).\n",
    "        3. Loop through season years from start_year to current_season_year.\n",
    "        4. Skip already-processed years (except eligible current season).\n",
    "        5. Fetch and parse standings HTML.\n",
    "        6. Append new data and save the updated CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    #Run Function to Identify Years to Process\n",
    "    current_season_year, process_current_season = get_current_season_year()\n",
    "    \n",
    "    #Run Function to Load Existing Data\n",
    "    existing_df, existing_years = load_existing_data(file_path, min_size_kb=1)\n",
    "\n",
    "    #Begin Scraping each Year\n",
    "    for year in range(start_year, current_season_year + 1):\n",
    "        if year in existing_years:\n",
    "            if year != current_season_year or not process_current_season:\n",
    "                print(f\"Skipping {year} — already processed or not in season.\")\n",
    "                continue\n",
    "\n",
    "        if year == current_season_year and not process_current_season:\n",
    "            print(f\"Skipping {year} — season hasn't started yet.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {year}...\")\n",
    "        soup = fetch_standings_html(year)\n",
    "        standings_df = parse_standings(soup, year)\n",
    "        existing_df = pd.concat([existing_df, standings_df], ignore_index=True)\n",
    "        existing_df = existing_df.sort_values(by=['Year','Conference','W'], ascending=[False, False, False])\n",
    "\n",
    "    #Update the Standings File\n",
    "    existing_df.to_csv(file_path, index=False)\n",
    "    print(\"Updated nba_standings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1960 — already processed or not in season.\n",
      "Skipping 1961 — already processed or not in season.\n",
      "Skipping 1962 — already processed or not in season.\n",
      "Skipping 1963 — already processed or not in season.\n",
      "Skipping 1964 — already processed or not in season.\n",
      "Skipping 1965 — already processed or not in season.\n",
      "Skipping 1966 — already processed or not in season.\n",
      "Skipping 1967 — already processed or not in season.\n",
      "Skipping 1968 — already processed or not in season.\n",
      "Skipping 1969 — already processed or not in season.\n",
      "Processing 1970...\n",
      "Skipping 1971 — already processed or not in season.\n",
      "Skipping 1972 — already processed or not in season.\n",
      "Skipping 1973 — already processed or not in season.\n",
      "Skipping 1974 — already processed or not in season.\n",
      "Skipping 1975 — already processed or not in season.\n",
      "Skipping 1976 — already processed or not in season.\n",
      "Skipping 1977 — already processed or not in season.\n",
      "Skipping 1978 — already processed or not in season.\n",
      "Skipping 1979 — already processed or not in season.\n",
      "Skipping 1980 — already processed or not in season.\n",
      "Skipping 1981 — already processed or not in season.\n",
      "Skipping 1982 — already processed or not in season.\n",
      "Skipping 1983 — already processed or not in season.\n",
      "Skipping 1984 — already processed or not in season.\n",
      "Skipping 1985 — already processed or not in season.\n",
      "Skipping 1986 — already processed or not in season.\n",
      "Skipping 1987 — already processed or not in season.\n",
      "Skipping 1988 — already processed or not in season.\n",
      "Skipping 1989 — already processed or not in season.\n",
      "Skipping 1990 — already processed or not in season.\n",
      "Skipping 1991 — already processed or not in season.\n",
      "Skipping 1992 — already processed or not in season.\n",
      "Skipping 1993 — already processed or not in season.\n",
      "Skipping 1994 — already processed or not in season.\n",
      "Skipping 1995 — already processed or not in season.\n",
      "Skipping 1996 — already processed or not in season.\n",
      "Skipping 1997 — already processed or not in season.\n",
      "Skipping 1998 — already processed or not in season.\n",
      "Skipping 1999 — already processed or not in season.\n",
      "Skipping 2000 — already processed or not in season.\n",
      "Skipping 2001 — already processed or not in season.\n",
      "Skipping 2002 — already processed or not in season.\n",
      "Skipping 2003 — already processed or not in season.\n",
      "Skipping 2004 — already processed or not in season.\n",
      "Skipping 2005 — already processed or not in season.\n",
      "Skipping 2006 — already processed or not in season.\n",
      "Skipping 2007 — already processed or not in season.\n",
      "Skipping 2008 — already processed or not in season.\n",
      "Skipping 2009 — already processed or not in season.\n",
      "Skipping 2010 — already processed or not in season.\n",
      "Skipping 2011 — already processed or not in season.\n",
      "Skipping 2012 — already processed or not in season.\n",
      "Skipping 2013 — already processed or not in season.\n",
      "Skipping 2014 — already processed or not in season.\n",
      "Skipping 2015 — already processed or not in season.\n",
      "Skipping 2016 — already processed or not in season.\n",
      "Skipping 2017 — already processed or not in season.\n",
      "Skipping 2018 — already processed or not in season.\n",
      "Skipping 2019 — already processed or not in season.\n",
      "Skipping 2020 — already processed or not in season.\n",
      "Skipping 2021 — already processed or not in season.\n",
      "Skipping 2022 — already processed or not in season.\n",
      "Skipping 2023 — already processed or not in season.\n",
      "Skipping 2024 — already processed or not in season.\n",
      "Skipping 2025 — already processed or not in season.\n",
      "Skipping 2026 — season hasn't started yet.\n",
      "Updated nba_standings.csv\n"
     ]
    }
   ],
   "source": [
    "#Run the main function to scrape standings\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
